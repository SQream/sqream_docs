.. _2020.1:

**************************
What's new in 2020.1
**************************

SQream DB v2020.1 contains lots of new features, improved performance, and bug fixes.

New features
================

Integrations
-----------------

* Load files directly from :ref:`S3 buckets<inserting_data>`

* Load files directly from :ref:`HDFS<inserting_data>`

* Import :ref:`ORC files<orc>`, through :ref:`external_tables`

* :ref:`Python driver (pysqream)<pysqream>` is now DB-API v2.0 compliant 

* Certified :ref:`Tableau JDBC connector (taco)<connect_to_tableau>`, now also :ref:`supported on MacOS<tableau_manual_installation>`

SQL support
---------------

* Added frames and frame exclusions to :ref:`window_functions`. This is available for preview, with more features coming in the next version

* New datatype - ``TEXT``, which replaces ``NVARCHAR`` directly with UTF-8 support and improved performance

* ``TEXT`` join keys are now supported

* Added lots of new :ref:`aggregate functions<aggregate_functions>`, including ``VAR_SAMP``, ``VAR_POP``, ``COVAR_POP``, etc.


Improvements and fixes
========================

* 207 bug fixes, including:
   
   - Improved performance of both inner and outer joins
   - Fixed wrong results on STDDEV (0 instead of ``NULL``)
   - Fixed wrong results on nested Parquet files
   - Fixed failing cast from ``VARCHAR`` to ``FLOAT``
   - Fix ``INSERT`` that would fail on nullable values and non-nullable columns in some scenarios
   - Improved memory consumption, so ``Out of GPU memory`` errors should not occur anymore
   - Reduced long compilation times for very complex queries
   - Improved ODBC reliability
   - Fixed situation where some logs would clip very long queries
   - Improved error messages when dropping a schema with many objects
   - Fixed situation where Spotfire would not show table names
   - Fixed situation where some queries with UTF-8 literals wouldn't run through Tableau over ODBC
   - Significantly improved cache freeing and memory allocation
   - Fixed situation in which a malformed time (``24:00:00``) would get incorrectly inserted from a CSV
   - Fixed race condition in which loading thousands of small files from HDFScaused a memory leak

* The :ref:`saved query<saved_queries>` feature can now be used with :ref:`insert` statements

* Faster "Deferred gather" algorithm for joins with text keys

* Faster filtering when using :ref:`datepart`

* Faster metadata tagging during load

* Fixed situation where some queries would get compiled twice

* :ref:`saved_queries` now support :ref:`insert` statements

* ``highCardinalityColumns`` can be configured to tell the system about :ref:`high selectivity<high_selectivity>` columns

* :ref:`sqream sql<sqream_sql_cli_reference>` starts up faster, can run on any Linux machine

* Additional CSV date formats (date parsers) added for compatibility

Behaviour changes
========================

* ``ClientCmd`` is now known as :ref:`sqream sql<sqream_sql_cli_reference>`

* ``NVARCHAR`` columns are now known as ``TEXT`` internally

* 
   Deprecated the ability to run ``SELECT`` and ``COPY`` at the same time on the same worker. This change is designed to protect against ``out of GPU memory`` issues.
   This comes with a configuration change, namely the ``limitQueryMemoryGB`` setting. See the operations section for more information.

* All logs are now unified into one log. See :ref:`logging` for more information

* Compression changes:
   
   - The latest version of SQream DB could select a different compression scheme if data is reloaded, compared to previous versions of SQream DB. This internal change improves performance.
   
   - With ``LZ4`` compression, the maximum chunk size is limited to 2.1GB. If the chunk size is bigger, another compression may be selected - primarily ``SNAPPY``.

* The following configuration flags have been deprecated:

   - ``addStatementRechunkerAfterGpuToHost``
   - ``increasedChunkSizeFactor``
   - ``gpuReduceMergeOutputFactor``
   - ``fullSortInputMemFactor``
   - ``reduceInputMemFactor``
   - ``distinctInputMemFactor``
   - ``useAutoMemFactors``
   - ``autoMemFactorsVramFactor``
   - ``catchNotEnoughVram``
   - ``useNetworkRechunker``
   - useMemFactorInJoinOutput

Operations
========================

* The client-server protocol has been updated to support faster data flow, and more reliable memory allocations on the client side. End users are required to use only the latest :ref:`sqream sql<sqream_sql_cli_reference>`, :ref:`java_jdbc`, and :ref:`odbc` drivers delivered with this version. See the :ref:`client driver download page<client_drivers>` for the latest drivers and connectors.

* When upgrading from a previous version of SQream DB (for example, v2019.2), the storage version must be upgraded using the :ref:`upgrade_storage_cli_reference` utility: ``./bin/upgrade_storage /path/to/storage/sqreamdb/``

* 
   A change in memory allocation behaviour in this version sees the introduction of a new setting, ``limitQueryMemoryGB``. This is an addition to the previous ``spoolMemoryGB`` setting.
 
   A good rule-of-thumb is to allow 5% system memory for other processes. The spool memory allocation should be around 90% of the total memory allocated.
   
   - ``limitQueryMemoryGB`` defines how much total system memory is used by the worker. The recommended setting is (``total host memory`` - 5%) / ``sqreamd workers on host``.

   - ``spoolMemoryGB`` defines how much memory is set aside for spooling, out of the total system memory allocated in ``limitQueryMemoryGB``. The recommended setting is 90% of the ``limitQueryMemoryGB``.
   
   For example, for a machine with 512GB of RAM and 4 workers, the recommended settings are:
   
   - ``limitQueryMemoryGB`` - ``⌊(512 * 0.95 / 4)⌋ → ~ 486 / 4 → 121``.
   
   - ``spoolMemoryGB`` - ``⌊( 0.9 * limitQueryMemoryGB )⌋ → ⌊( 0.9 * 121 )⌋ → 108``

   Example settings per-worker, for 512GB of RAM and 4 workers:
   
   .. code-block:: none
      
      "runtimeGlobalFlags": {
         "limitQueryMemoryGB" : 121,
         "spoolMemoryGB" : 108

   

 
Known Issues & Limitations
================================

* An invalid formatted CSV can cause an ``insufficient memory`` error on a :ref:`copy_from` statement if a quote isn't closed and the file is much larger than system memory.

* ``TEXT`` columns cannot be used in a window functions' partition

* Parsing errors are sometimes hard to read - the location points to the wrong part of the statement

* LZ4 compression may not be applied correctly on very large ``VARCHAR`` columns, which decreases performance

* Using ``SUM`` on very large numbers in window functions can error (``overflow``) when not used with an ``ORDER BY`` clause

* Slight performance decrease with :ref:`dateadd` in this version (<4%)

* Operations on Snappy-compressed ORC files are slower than their Parquet equivalents.


Upgrading to v2020.1
========================

Versions are available for IBM POWER9, RedHat (CentOS) 7, Ubuntu 18.04, and other OSs via Docker.

Contact your account manager to get the latest release of SQream DB.